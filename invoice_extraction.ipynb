{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81ab120-3ad6-4540-a4c5-521d2b0f90ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutLM initialization failed: microsoft/layoutlmv2-finetuned-funsd is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.\n",
      "Falling back to OCR-only mode with heuristic extraction\n",
      "Starting processing of C:\\Users\\HP/Desktop/invoice/batch1_1\n",
      "Results will be saved to C:\\Users\\HP/Desktop/invoice/batch1_1_results\n",
      "Found 10 images to process in C:\\Users\\HP\\Desktop\\invoice\\batch1_1\n",
      "\n",
      "Processing batch1-0001.jpg...\n",
      "Using OCR-only fallback for field extraction...\n",
      "Completed processing batch1-0001.jpg\n",
      "Saved results to C:\\Users\\HP\\Desktop\\invoice\\batch1_1_results\\batch1-0001.json\n",
      "\n",
      "Processing batch1-0002.jpg...\n",
      "Using OCR-only fallback for field extraction...\n",
      "Completed processing batch1-0002.jpg\n",
      "Saved results to C:\\Users\\HP\\Desktop\\invoice\\batch1_1_results\\batch1-0002.json\n",
      "\n",
      "Processing batch1-0003.jpg...\n",
      "Using OCR-only fallback for field extraction...\n",
      "Completed processing batch1-0003.jpg\n",
      "Saved results to C:\\Users\\HP\\Desktop\\invoice\\batch1_1_results\\batch1-0003.json\n",
      "\n",
      "Processing batch1-0004.jpg...\n",
      "Using OCR-only fallback for field extraction...\n",
      "Completed processing batch1-0004.jpg\n",
      "Saved results to C:\\Users\\HP\\Desktop\\invoice\\batch1_1_results\\batch1-0004.json\n",
      "\n",
      "Processing batch1-0005.jpg...\n",
      "Using OCR-only fallback for field extraction...\n",
      "Completed processing batch1-0005.jpg\n",
      "Saved results to C:\\Users\\HP\\Desktop\\invoice\\batch1_1_results\\batch1-0005.json\n",
      "\n",
      "Processing batch1-0006.jpg...\n",
      "Using OCR-only fallback for field extraction...\n",
      "Completed processing batch1-0006.jpg\n",
      "Saved results to C:\\Users\\HP\\Desktop\\invoice\\batch1_1_results\\batch1-0006.json\n",
      "\n",
      "Processing batch1-0007.jpg...\n",
      "Using OCR-only fallback for field extraction...\n",
      "Completed processing batch1-0007.jpg\n",
      "Saved results to C:\\Users\\HP\\Desktop\\invoice\\batch1_1_results\\batch1-0007.json\n",
      "\n",
      "Processing batch1-0008.jpg...\n",
      "Using OCR-only fallback for field extraction...\n",
      "Completed processing batch1-0008.jpg\n",
      "Saved results to C:\\Users\\HP\\Desktop\\invoice\\batch1_1_results\\batch1-0008.json\n",
      "\n",
      "Processing batch1-0009.jpg...\n",
      "Using OCR-only fallback for field extraction...\n",
      "Completed processing batch1-0009.jpg\n",
      "Saved results to C:\\Users\\HP\\Desktop\\invoice\\batch1_1_results\\batch1-0009.json\n",
      "\n",
      "Processing batch1-0010.jpg...\n",
      "Using OCR-only fallback for field extraction...\n",
      "Completed processing batch1-0010.jpg\n",
      "Saved results to C:\\Users\\HP\\Desktop\\invoice\\batch1_1_results\\batch1-0010.json\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re  \n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Dict  \n",
    "from paddleocr import PaddleOCR\n",
    "from transformers import LayoutLMv2Processor, LayoutLMv2ForTokenClassification\n",
    "from PIL import Image\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "class InvoiceExtractor:\n",
    "    def __init__(self, hf_token=None):\n",
    "    \n",
    "        self.ocr = PaddleOCR(use_angle_cls=True, lang='en', show_log=False)\n",
    "        \n",
    "        try:\n",
    "            if hf_token:\n",
    "                login(token=hf_token)\n",
    "            \n",
    "           \n",
    "            self.processor = LayoutLMv2Processor.from_pretrained(\n",
    "                \"microsoft/layoutlmv2-base-uncased\",\n",
    "                use_auth_token=hf_token if hf_token else None\n",
    "            )\n",
    "            self.model = LayoutLMv2ForTokenClassification.from_pretrained(\n",
    "                \"microsoft/layoutlmv2-finetuned-funsd\",\n",
    "                use_auth_token=hf_token if hf_token else None\n",
    "            )\n",
    "            \n",
    "            self.use_layoutlm = True\n",
    "            print(\"LayoutLM model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"LayoutLM initialization failed: {str(e)}\")\n",
    "            print(\"Falling back to OCR-only mode with heuristic extraction\")\n",
    "            self.use_layoutlm = False\n",
    "        \n",
    "      \n",
    "        self.label2id = {\n",
    "            \"O\": 0,\n",
    "            \"B-INVOICE_NUMBER\": 1,\n",
    "            \"I-INVOICE_NUMBER\": 2,\n",
    "            \"B-INVOICE_DATE\": 3,\n",
    "            \"I-INVOICE_DATE\": 4,\n",
    "            \"B-SELLER_NAME\": 5,\n",
    "            \"I-SELLER_NAME\": 6,\n",
    "            \"B-SELLER_ADDRESS\": 7,\n",
    "            \"I-SELLER_ADDRESS\": 8,\n",
    "            \"B-TOTAL_AMOUNT\": 9,\n",
    "            \"I-TOTAL_AMOUNT\": 10,\n",
    "            \"B-LINE_ITEM\": 11,\n",
    "            \"I-LINE_ITEM\": 12\n",
    "        }\n",
    "        self.id2label = {v: k for k, v in self.label2id.items()}\n",
    "        \n",
    "       \n",
    "        self.fallback_patterns = {\n",
    "            'invoice_number': r'(invoice\\s*no[:.]?\\s*)([A-Za-z0-9-]+)',\n",
    "            'invoice_date': r'(date\\s*of\\s*issue[:.]?\\s*)(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})',\n",
    "            'seller_name': r'(seller[:.]?\\s*)([\\w\\s,.&-]+)',\n",
    "            'total_amount': r'(total\\s*)\\$?\\s*([\\d,.]+)',\n",
    "            'vat_amount': r'(vat\\s*)\\$?\\s*([\\d,.]+)'\n",
    "        }\n",
    "\n",
    "    def preprocess_image(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Preprocess image for better OCR results\"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not read image at {image_path}\")\n",
    "            \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.adaptiveThreshold(\n",
    "            gray, 255, \n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "            cv2.THRESH_BINARY, 11, 2\n",
    "        )\n",
    "        return thresh\n",
    "    \n",
    "    def extract_text_with_paddleocr(self, image_path: str) -> List[Dict]:\n",
    "        \"\"\"Extract text and bounding boxes using PaddleOCR\"\"\"\n",
    "        try:\n",
    "            processed_img = self.preprocess_image(image_path)\n",
    "            temp_path = \"temp_preprocessed.jpg\"\n",
    "            cv2.imwrite(temp_path, processed_img)\n",
    "            \n",
    "            result = self.ocr.ocr(temp_path, cls=True)\n",
    "            os.remove(temp_path)\n",
    "            \n",
    "            ocr_results = []\n",
    "            if result and result[0]:\n",
    "                for line in result[0]:\n",
    "                    if line and len(line) >= 2:\n",
    "                        text = line[1][0]\n",
    "                        confidence = line[1][1]\n",
    "                        bbox = line[0]\n",
    "                        ocr_results.append({\n",
    "                            \"text\": text,\n",
    "                            \"confidence\": float(confidence),\n",
    "                            \"bbox\": [[float(p[0]), float(p[1])] for p in bbox]\n",
    "                        })\n",
    "            return ocr_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error in PaddleOCR: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def process_with_layoutlm(self, image_path: str, ocr_results: List[Dict]) -> Dict:\n",
    "        \"\"\"Process OCR results with LayoutLM for structured extraction\"\"\"\n",
    "        if not self.use_layoutlm:\n",
    "            return {}\n",
    "            \n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            words = [res[\"text\"] for res in ocr_results]\n",
    "            boxes = [res[\"bbox\"] for res in ocr_results]\n",
    "            \n",
    "            normalized_boxes = []\n",
    "            for box in boxes:\n",
    "                x_coords = [p[0] for p in box]\n",
    "                y_coords = [p[1] for p in box]\n",
    "                x0, x1 = min(x_coords), max(x_coords)\n",
    "                y0, y1 = min(y_coords), max(y_coords)\n",
    "                normalized_boxes.append([x0, y0, x1, y1])\n",
    "            \n",
    "            encoding = self.processor(\n",
    "                image, words, boxes=normalized_boxes,\n",
    "                return_offsets_mapping=True, padding=\"max_length\",\n",
    "                truncation=True, max_length=512, return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(\n",
    "                    input_ids=encoding[\"input_ids\"],\n",
    "                    bbox=encoding[\"bbox\"],\n",
    "                    attention_mask=encoding[\"attention_mask\"],\n",
    "                    token_type_ids=encoding[\"token_type_ids\"],\n",
    "                    image=encoding[\"image\"]\n",
    "                )\n",
    "            \n",
    "            predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "            results = {}\n",
    "            current_label = None\n",
    "            current_text = \"\"\n",
    "            \n",
    "            for pred, word in zip(predictions, words):\n",
    "                label = self.id2label.get(pred, \"O\")\n",
    "                \n",
    "                if label.startswith(\"B-\"):\n",
    "                    if current_label:\n",
    "                        results[current_label] = current_text.strip()\n",
    "                    current_label = label[2:]\n",
    "                    current_text = word\n",
    "                elif label.startswith(\"I-\") and current_label == label[2:]:\n",
    "                    current_text += \" \" + word\n",
    "                else:\n",
    "                    if current_label:\n",
    "                        results[current_label] = current_text.strip()\n",
    "                        current_label = None\n",
    "                        current_text = \"\"\n",
    "            \n",
    "            if current_label:\n",
    "                results[current_label] = current_text.strip()\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error in LayoutLM processing: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def extract_with_fallback(self, text: str) -> Dict:\n",
    "        \"\"\"Fallback extraction using regex patterns when LayoutLM fails\"\"\"\n",
    "        results = {}\n",
    "        for field, pattern in self.fallback_patterns.items():\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                results[field.upper()] = match.group(2).strip()\n",
    "        return results\n",
    "\n",
    "    def extract_line_items(self, ocr_results: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Extract line items using table detection heuristics\"\"\"\n",
    "        try:\n",
    "            # Group by approximate y-coordinate (same line)\n",
    "            line_groups = {}\n",
    "            for res in ocr_results:\n",
    "                y_center = sum(p[1] for p in res[\"bbox\"]) / 4\n",
    "                found_group = False\n",
    "                for y in line_groups:\n",
    "                    if abs(y - y_center) < 10:  # 10 pixel tolerance\n",
    "                        line_groups[y].append(res)\n",
    "                        found_group = True\n",
    "                        break\n",
    "                if not found_group:\n",
    "                    line_groups[y_center] = [res]\n",
    "            \n",
    "            \n",
    "            sorted_lines = [line_groups[y] for y in sorted(line_groups)]\n",
    "            \n",
    "           \n",
    "            line_items = []\n",
    "            for line in sorted_lines:\n",
    "                line.sort(key=lambda x: x[\"bbox\"][0][0])\n",
    "                \n",
    "               \n",
    "                if len(line) >= 4 and line[0][\"text\"].replace(\".\", \"\").isdigit():\n",
    "                    line_items.append({\n",
    "                        \"item_no\": line[0][\"text\"].replace(\".\", \"\"),\n",
    "                        \"description\": line[1][\"text\"],\n",
    "                        \"quantity\": line[2][\"text\"],\n",
    "                        \"unit_price\": line[3][\"text\"],\n",
    "                        \"total\": line[4][\"text\"] if len(line) > 4 else \"\"\n",
    "                    })\n",
    "            \n",
    "            return line_items\n",
    "        except Exception as e:\n",
    "            print(f\"Error in line item extraction: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def process_invoice(self, image_path: str) -> Dict:\n",
    "        \"\"\"Process single invoice image\"\"\"\n",
    "        try:\n",
    "            print(f\"\\nProcessing {os.path.basename(image_path)}...\")\n",
    "            ocr_results = self.extract_text_with_paddleocr(image_path)\n",
    "            text = \" \".join([res[\"text\"] for res in ocr_results])\n",
    "            \n",
    "            if self.use_layoutlm:\n",
    "                print(\"Using LayoutLM for field extraction...\")\n",
    "                layout_results = self.process_with_layoutlm(image_path, ocr_results)\n",
    "            else:\n",
    "                print(\"Using OCR-only fallback for field extraction...\")\n",
    "                layout_results = self.extract_with_fallback(text)\n",
    "            \n",
    "            line_items = self.extract_line_items(ocr_results)\n",
    "            if line_items:\n",
    "                layout_results[\"LINE_ITEMS\"] = line_items\n",
    "            \n",
    "            # Add OCR confidence summary\n",
    "            if ocr_results:\n",
    "                confidences = [res[\"confidence\"] for res in ocr_results]\n",
    "                layout_results[\"OCR_QUALITY\"] = {\n",
    "                    \"average_confidence\": sum(confidences)/len(confidences),\n",
    "                    \"lowest_confidence\": min(confidences)\n",
    "                }\n",
    "            \n",
    "            print(f\"Completed processing {os.path.basename(image_path)}\")\n",
    "            return layout_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing invoice: {str(e)}\")\n",
    "            return {\"error\": str(e), \"file\": os.path.basename(image_path)}\n",
    "\n",
    "    def batch_process(self, image_dir: str, output_dir: str, max_files: int = None) -> None:\n",
    "        \"\"\"Process all images in a directory\"\"\"\n",
    "        image_dir = Path(image_dir)\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        \n",
    "        image_extensions = ['*.png', '*.jpg', '*.jpeg']\n",
    "        image_paths = []\n",
    "        for ext in image_extensions:\n",
    "            image_paths.extend(list(image_dir.glob(ext)))\n",
    "        \n",
    "        \n",
    "        if max_files is not None:\n",
    "            image_paths = image_paths[:max_files]\n",
    "        \n",
    "        print(f\"Found {len(image_paths)} images to process in {image_dir}\")\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                result = self.process_invoice(str(img_path))\n",
    "                output_path = output_dir / f'{img_path.stem}.json'\n",
    "                \n",
    "                with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "                \n",
    "                print(f'Saved results to {output_path}')\n",
    "            except Exception as e:\n",
    "                print(f'Failed to process {img_path.name}: {str(e)}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    extractor = InvoiceExtractor()\n",
    "    \n",
    "    \n",
    "    input_folder = os.path.expanduser(\"~/Desktop/invoice/batch1_1\")\n",
    "    output_folder = os.path.expanduser(\"~/Desktop/invoice/batch1_1_results\")\n",
    "    \n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    print(f\"Starting processing of {input_folder}\")\n",
    "    print(f\"Results will be saved to {output_folder}\")\n",
    "    \n",
    "    extractor.batch_process(input_folder, output_folder, max_files=10)\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc253c7-0ece-4f47-ba77-415bc5464779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invoice_ml",
   "language": "python",
   "name": "invoice_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
